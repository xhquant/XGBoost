{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 深入理解xgboost六"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 毒蘑菇二分类问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fmap(file_name):\n",
    "    fmap = {}\n",
    "    nmap = {}\n",
    "    \n",
    "    for line in open(file_name):\n",
    "        # 以空字符（空格、换行、制表符等）为分割符分割一行\n",
    "        arr = line.split()\n",
    "        # 解析每行中的特征名称、取值等，其中，idx为初始特征索引，ftype为初始特征名称，content为该特征取值说明\n",
    "        if arr[0].find(\".\") != -1:\n",
    "            idx = int(arr[0].strip(\".\"))\n",
    "            assert idx not in fmap\n",
    "            fmap[idx] = {}\n",
    "            ftype = arr[1].strip(\":\")\n",
    "            content = arr[2]\n",
    "        else:\n",
    "            content = arr[0]\n",
    "            \n",
    "        # 解析取值\n",
    "        # fmap是为特征的每个取值分配一个唯一标示的索引，nmap为处理后的新特征重新命名\n",
    "        for it in content.split(\",\"):\n",
    "            if it.strip() == \"\":\n",
    "                continue\n",
    "            key, value = it.split(\"=\")\n",
    "            fmap[idx][value] = len(nmap) + 1\n",
    "            nmap[len(nmap)] = ftype + \"=\" + key\n",
    "    return fmap, nmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_nmap(file_object, nmap):\n",
    "    for i in range(len(nmap)):\n",
    "        file_object.write(\"%d\\t%s\\ti\\n\" % (i, nmap[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'b': 1, 'c': 2, 'x': 3, 'f': 4, 'k': 5, 's': 6}, 2: {'f': 7, 'g': 8, 'y': 9, 's': 10}, 3: {'n': 11, 'b': 12, 'c': 13, 'g': 14, 'r': 15, 'p': 16, 'u': 17, 'e': 18, 'w': 19, 'y': 20}, 4: {'t': 21, 'f': 22}, 5: {'a': 23, 'l': 24, 'c': 25, 'y': 26, 'f': 27, 'm': 28, 'n': 29, 'p': 30, 's': 31}, 6: {'a': 32, 'd': 33, 'f': 34, 'n': 35}, 7: {'c': 36, 'w': 37, 'd': 38}, 8: {'b': 39, 'n': 40}, 9: {'k': 41, 'n': 42, 'b': 43, 'h': 44, 'g': 45, 'r': 46, 'o': 47, 'p': 48, 'u': 49, 'e': 50, 'w': 51, 'y': 52}, 10: {'e': 53, 't': 54}, 11: {'b': 55, 'c': 56, 'u': 57, 'e': 58, 'z': 59, 'r': 60, '?': 61}, 12: {'f': 62, 'y': 63, 'k': 64, 's': 65}, 13: {'f': 66, 'y': 67, 'k': 68, 's': 69}, 14: {'n': 70, 'b': 71, 'c': 72, 'g': 73, 'o': 74, 'p': 75, 'e': 76, 'w': 77, 'y': 78}, 15: {'n': 79, 'b': 80, 'c': 81, 'g': 82, 'o': 83, 'p': 84, 'e': 85, 'w': 86, 'y': 87}, 16: {'p': 88, 'u': 89}, 17: {'n': 90, 'o': 91, 'w': 92, 'y': 93}, 18: {'n': 94, 'o': 95, 't': 96}, 19: {'c': 97, 'e': 98, 'f': 99, 'l': 100, 'n': 101, 'p': 102, 's': 103, 'z': 104}, 20: {'k': 105, 'n': 106, 'b': 107, 'h': 108, 'r': 109, 'o': 110, 'u': 111, 'w': 112, 'y': 113}, 21: {'a': 114, 'c': 115, 'n': 116, 's': 117, 'v': 118, 'y': 119}, 22: {'g': 120, 'l': 121, 'm': 122, 'p': 123, 'u': 124, 'w': 125, 'd': 126}}\n"
     ]
    }
   ],
   "source": [
    "# 开始解析数据\n",
    "fmap, nmap = load_fmap(\"dataset/agaricus-lepiota/agaricus-lepiota.fmap\")\n",
    "print(fmap)\n",
    "\n",
    "# 保存处理后的新特征索引和名称的映射\n",
    "file_object = open(\"dataset/agaricus-lepiota/feature_map.txt\", \"w\")\n",
    "write_nmap(file_object, nmap)\n",
    "file_object.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过新特征索引处理原始数据，生成转化后的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_object = open(\"dataset/agaricus-lepiota/agaricus.txt\", \"w\")\n",
    "\n",
    "for line in open(\"dataset/agaricus-lepiota/agaricus-lepiota.data\"):\n",
    "    arr = line.split(\",\")\n",
    "    if arr[0] == \"p\":\n",
    "        file_object.write(\"1\")\n",
    "    else:\n",
    "        assert arr[0] == \"e\"\n",
    "        file_object.write(\"0\")\n",
    "    \n",
    "    for i in range(1, len(arr)):\n",
    "        file_object.write(\" %d:1\" % (fmap[i][arr[i].strip()]))\n",
    "    file_object.write(\"\\n\")\n",
    "\n",
    "file_object.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost二分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_svmlight_file(\"dataset/agaricus-lepiota/agaricus.txt\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train = xgb.DMatrix(X_train, y_train)\n",
    "xgb_test = xgb.DMatrix(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数\n",
    "params = {\"objective\": \"binary:logistic\",\n",
    "          \"booster\": \"gbtree\",\n",
    "          \"max_depth\": 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round = 10\n",
    "watch_list = [(xgb_train, \"training\"), (xgb_test, \"testing\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttraining-logloss:0.43920\ttesting-logloss:0.44076\n",
      "[1]\ttraining-logloss:0.29856\ttesting-logloss:0.30134\n",
      "[2]\ttraining-logloss:0.20988\ttesting-logloss:0.21370\n",
      "[3]\ttraining-logloss:0.15053\ttesting-logloss:0.15531\n",
      "[4]\ttraining-logloss:0.10947\ttesting-logloss:0.11515\n",
      "[5]\ttraining-logloss:0.08039\ttesting-logloss:0.08693\n",
      "[6]\ttraining-logloss:0.05937\ttesting-logloss:0.06536\n",
      "[7]\ttraining-logloss:0.04419\ttesting-logloss:0.04978\n",
      "[8]\ttraining-logloss:0.03303\ttesting-logloss:0.03809\n",
      "[9]\ttraining-logloss:0.02472\ttesting-logloss:0.02874\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(params=params, dtrain=xgb_train, num_boost_round=num_round, evals=watch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"model/agaricus.model\")\n",
    "model.dump_model(\"model/agaricus.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster = xgb.Booster()\n",
    "booster.load_model(\"model/agaricus.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02283082, 0.97443706, 0.97443706, ..., 0.97741723, 0.02283082,\n",
       "       0.02367815], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = booster.predict(xgb_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          有毒       1.00      0.99      1.00       805\n",
      "          无毒       0.99      1.00      1.00       820\n",
      "\n",
      "    accuracy                           1.00      1625\n",
      "   macro avg       1.00      1.00      1.00      1625\n",
      "weighted avg       1.00      1.00      1.00      1625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.round(y_pred)\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred, labels=[1, 0], target_names=[\"有毒\", \"无毒\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster.dump_model(\"model/agaricus.nice.model\", \"dataset/agaricus-lepiota/feature_map.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
